网络基础 

http与https：
 
 1. 通信过程容易被劫持，因此通过数据加密进行保护
 分为 对称加密 非对称加密
 2. 如果通信过程中一直采用对称加密算法，很容易被破解
 3. 因此最好采用非对称加密算法，但是非对称加密算法解析的性能比较低
 4. 因此更进一步： 采用动态协商对称加密算法，协商的过程采用非对称加密算法进行加密
 5. 非对称加密算法由 服务端生成一个公钥，然后获取CA颁发的整数和私钥，将公钥发给对方，对方用公钥加密，
 自己用私钥解密
 6. 因为公钥容易被劫持，所以用签名证书的方式证明身份，防止证书被劫持，因此需要权威机构办法


udp面向数据报
1. 特性取决于udp数据报长度这个字段  uint16_t决定了udp整个数据报长度不能大于64k,若大于的话，两个字节就不够存了
2. 因为udp有数据报长度的限制，因此数据过大，则需要用户在应用层进行数据分包
3. udp并不保证数据的可靠，有序的到达，因此可能是乱序，需要用户在应用层进行包序管理
4. udp在sendto发送数据的时候将数据发送缓冲区，直接封装头部，将数据发送出去


为什么要做这个项目？(初衷)
让网络中的任意两台主机之间可以互相下载文件
 

设计的过程中就会包括两个大的模块：
1. 客户端模块： 查看共享主机 -> 获取主机文件列表 -> 从指定主机下载文件
2. 服务端模块：针对于客户端的请求提供客户端请求服务


一定范围内的定长内存池：
解决的问题： 性能问题 + 应用范围更广的问题  利用哈希映射关系
没有解决的问题： 内存碎片问题， 将内存切成很多个小块的内存，8字节的内存，
全部挂载自由链表的8字节对应的下面，所以当申请更大的内存时，就不能从内存中申请，
合并的过程中也很难合并，因为内存是连续的，归还的时候也要将内存前后的页进行合并。

malloc解决的是 性能问题 + 内存碎片(系统提供的级别)
未解决的是 ： 并发的malloc

内存碎片是 ： 
将大内存切成小内存了，使得没有剩余的空间可以申请了，所以要进行合并。
所以 要以 页 为单位合并

Span:
{
	pageid; //页号
	free_list; // 自由链表
	use_count; // 使用计数
}

page cache以页为单位 申请内存，那么一次申请几页呢？
没 不到一页就给1页， 不超过2页 就给2页
以一个span的方式 给你，会告诉你这个页的页号，知道页号就知道这块空间的地址


socket编程中有哪些系统函数调用？

多个线程读取一个数组里的一段字，要求每个人读取都是连续的，并且读出来都是一个完整的句子怎么做？

linux下的虚拟内存管理：
1. 每一个进程都有一个虚拟地址空间，进程访问虚拟地址空间并不是真正的物理地址
2. 虚拟内存可以通过每一个进程上的页表与物理地址进行映射，获得真正的物理地址
3. 如果逻辑地址对应的物理地址不存在与内存，则会产生缺页中断，
真正分配物理地址，同时更新进程的页表；如果物理内存已经耗尽，
根据页面替换算法淘汰部分页面 至物理磁盘中


既然堆内的内存不能直接释放，为什么不全部使用mmap来分配？?

缺页中断是内核行为，会导致内核的cpu消耗过大，另外mmap分配小内存，会导致分片更多。
内核的管理负担更大。

而堆是一个连续的空间，并且堆内碎片由于没有归还给OS，如果可重用碎片，
再次访问该内存很可能不需产生任何系统调用和缺页中断，这将大大降低 CPU 的消耗

查看linux下系统资源占用常用命令？

top
 PID 		USER	 PR	    	NI	       VIRT       RES          SHR      S     CPU        MEM 
 进程标识  所有者  优先级	  优先级数值   虚拟内存  实际物理内存                CPU占有率

p：CPU使用大小进行排序
T: 根据时间，累计时间排序
q: 退出top命令
m：切换显示内存信息


free命令
1. 作用： 显示内存的使用情况

查看磁盘资源的使用情况：df
1. 统一磁盘整体情况，包括磁盘大小已使用，可用
1) 查看当前目录：
df -h (-h -human,人性化的查看)

2. 具体查看文件夹下的占用情况
du -h 

一个统计整体磁盘情况df，一个看单独目录点用情况dh

linux下查看某个端口状态

netstat 所有建立连接的 established
netstat -a 所有服务端的正在监听，或者简历连接的的端口信息

netstat -anp | grep 端口号 (p就是port端口)

静态库和动态库的区别？

静态库(.a)文件 在链接阶段，会将汇编生成的目标文件.o文件与引用的库打包到可执行文件中。
动态库(.so)文件 在链接阶段， 只是将符号表定位符等消息拷贝到可执行文件，运行的时候才加载动态库。

1.可执行文件的大小是不一样的(静态链接的可执行文件要比动态链接的可执行文件大得多，因为静态链接文件是将静态库中的东西拷贝了一份
，而 动态链接仅仅是 复制了一些重定位和符号表信息)
2.占用的磁盘大小是不一样的
如果有多个可执行文件，那么静态库中的同一函数的代码就会被复制多份，而动态库的代码只有一份)
3. 扩展性和兼容性不同(对于动态链接的文件，只需要更新动态库本身，方便升级和部署)
4. 依赖性不同
5. 静态链接的加载速度比动态链接快


用户态 对 内核态 是不信任的。

epoll从内核到用户态是拷贝的，不是虚拟内存共享的，返回的时候，用户态为了接受就绪事件，其实自己已经定义了缓冲区。
epoll_wait返回的时候，对于就绪事件其实是内存拷贝的
我下来的时候看了epoll源码，发现没有从内核态到用户态的拷贝，并没有调用 mmap系统调用这个函数，
所以根本不会存在 共享内存的 epoll的实现， 而是调用 put_user 这个函数 将内核拷贝到 用户态的 
 
1. 指针就是地址，在win32下，一共有32位地址线，所以有2^32次方的地址单位
指针就可以指向 函数也可以指向变量，通过指针间接的访问变量或者函数

2. struct 和 union 
1)定义变量的时候，struct需要分号定义，而union需要，定义
2) struct结构体需要内存对齐，而union不需要，union中的所有变量共享同一块内存
3) struct和union都可以实现继承，但是union不能实现虚函数，多态
4)

3. 内存对齐 是 有两个原因吧 
硬件原因：		不是每一种cpu都可以访问内存中每一个位置
				 依次访问要尽量向4,8对齐，这样一次就可以去除数据，不用两次方寸
cpu架构的原因: 	 cpu中8个blank并行工作效率会很高，所以要尽力对齐到8字节

4. 内存对齐：
1. 第一个变量从0开始时
对齐数是指 编译器的对齐数 与 变量的对齐数的最小值
2. 每一次对齐的时候 都要对齐到对齐数 倍数的整数值
3. 最后的对齐数 为 最大的对齐数的整数倍


什么是缺页异常？
页式管理机制通过页面目录，将一个线性地址转换为物理地址，但并不是每一次都能访问到相应的物理内存单元，
这样映射就失败了，会产生缺页异常

页缺失，在分页机制的操作系统中，cpu通过总线可以访问总线上的所有外设，
当MMU没有开启的时候，cpu发出的逻辑地址被内存芯片 底脚 接收
转换为 物理地址，
由MMU将虚拟地址转换成物理地址再从地址总线上发出，MMU上的这种虚拟地址和物理地址的
转换关系是需要创建的，并且MMU还可以设置这个物理页是否可以进行写操作，当没有创建
一个虚拟地址到物理地址的映射，或者创建了这样的映射，但那个物理页不可写的时候，
MMU将会通知CPU产生了一个缺页异常。


IO密集型程序的时候，而单线程的话此时还是在一个一个等待的， ？？ 时间片怎么办？
是一定串行化的吗 ？？

互斥锁使用的注意事项：
1. 锁尽量只保护对临界资源的访问操作
2. 在任意有可能退出的地方退出前都要进行解锁。

银行家算法维护的四张表？

条件变量？
线程在满足资源访问条件的时候才能去访问资源，否则挂起线程，直到条件满足，才会从等待队列上唤醒线程

1.条件变量需要搭配互斥锁去使用，因为条件变量是否满足条件本身就是一个临界资源，需要搭配互斥锁保护起来，
2.条件变量的使用一定是在多个执行流里面(多个线程)，并且是不同角色的执行流里面。一个线程的条件不满足，在等待队列上等待的时候，得有别的线程促使你这个线程条件满足
3.用户的条件判断需要用while循环进行判断，因为唤醒signal接口唤醒多个线程，
有可能都等待在锁上，解锁后，这时候可能在线程不具备访问条件的情况下
加锁成功，并访问资源。

4. 不同角色的线程应该挂载到不同的等待队列上进行等待，唤醒的时候，就比较有目的的唤醒。因此多个角色要使用多个条件变量

为什么pthread_cond_wait(&cond,&mutex)中要有互斥锁变量？

什么时候该等待 要有一个条件判断，该有别的线程促使这个条件满足，
所以条件的判断本身就是一个临界资源，多个线程对这个临界资源争抢访问、(厨师和吃面人都要判断当前是否要有面，一个线程促使
另一个线程满足此条件)
所以应该对这个变量进行保护，需要用到互斥锁变量。

生产者消费者模型：
1. 支持忙闲不均 ： 生产的数据完全可以放到缓冲区队列中，尽管生产与消费的速度不一致，所以支持忙闲不均吗，也不会丢失数据
2. 支持并发： 线程安全循环队列中
3. 解耦合： 生产者不用直接与消费者之间相关联，中间多加了一层缓冲队列，所以减小之间的关联。
一个场合， 两类角色， 三种关系

一个场合： 生产者 缓冲区队列 消费者
两类角色： 生产 消费者
三种关系： 生产与生产者之间 互斥
		   生产与消费者之间 同步
		   消费与消费者之间 互斥

信号量与条件变量的区别：
1. 信号量的同步是由自己的原子计数器实现计数的，不需要用户的自行判断，而条件变量的条件判断是由用户自身代码逻辑控制的。
也就是说需要用户自身去判断
2.并且条件变量使用的是外部用户的条件判断，必须是搭配互斥锁一起使用，而信号量，是通过自身的条件判断，在内部保证了操作的原子性。so


sem_t  计数器 等待队列 保证计数安全的其它锁

int sem_init(sem_t*sem, int pshared, unsigned int value);
							0 / 1 进程间
因为是一个库，线程间就可以使用全局变量，进程间，实际上是申请了一块共享内存（包含了计数器和共享队列）。
sem_wait(sem_t* sem);
sem_post(sem_t* sem);

class BlockQueue
{
	queue<int> _q;
	int maxQ = 10;
	int _capacity;
	pthread_cond_t _cond_productor; //生产者等待队列
	pthread_cond_t _cond_consumer; // 消费者等待队列
	pthread_mutex_t mtx;
public:
	BlockQueue(int que_num = maxQ)
		:_capacity(que_num)
		{
			pthread_mutex_init(&mtx,NULL):
			pthread_cond_init(&_cond_consumer,NULL);
			pthread_cond_init(&_cond_productor,NULL);
		}
	~BlockQueue()
	{
		pthread_mutex_destroy(&mtx);
		pthread_cond_destroy(&cond);
		pthread_mutex_destroy(&cond);
		destroy
		destroy
		destroy;
		destroy;
		destroy;
		destroy;
		pthraph;
		
		pthread_cond_destroy(pthread_cond_productor);
		
	}
	
	
	bool QueuePush(int& data)
	{
		pthread_mutex_lock(&mtx);
		while(queue.size() == _capacity)
		{
			pthread_cond_wait(&_cond_productor,&mtx);
		}
		_queue.push(data);
		pthread_mutex_unlock(&mtx);
		pthread_cond_siginal(&_cond_consumer);
		return true;
		
	}
	bool QueuePop(int &data)
	{
		
	}
	void *thr_consumer(void* arg)
	{
		BlockQueue* queue = (BlockQueue*)arg;
		while(1)
		{
			int data;
			queue->QueuePush(data);
			
		}
		return nullptr;
	}
	
	void *thr_productor(void* arg)
	{
		BlockQueue* queue = (BlockQueue*)arg;
		while(1)
		{
			int data;
			queue->QueuePop(data);
		}
		return nullptr;
	}
};

环境变量： export

环境变量是保存系统配置环境参数的变量，可以让环境的配置更加的灵活。
环境变量就是一个指定一个目录，运行软件的时候，相关的程序将会按照该目录寻找相关文件。
设置动态库的加载路径，不用每次都从安装路径中加载。

建堆的时间复杂度: O(N)

linux下的文件操作 chmod .. 还有 命令。


1. int socket(int domain, int type, int protocol)

2. bind

//建立连接的过程由操作系统完成 监听套接字---只负责于客户端进行第一次连接
3. listen (backlog：已完成连接的队列--限制同一时间的并发连接数)

//阻塞操作，获取不到就一直等待
4. accept(int sockfd, struct sockaddr* addr(客户地址信息)，socklen_t* addrlen)

// tcp通信不用告诉对端地址信息，因为socket里面有对端的地址和端口信息
5. ssize_t send(int sockfd, char* buf, int len, int flag) 

// 接收信息的时候也不用获取 源目的地址，因为套接字中含有
6. ssize_t recv(int sockfd, char* buf, int len, int flag)



半连接状态：
指TCP状态为SYN_RCVD的状态。服务器处于listen状态受到客户端SYN报文时放入半连接队列中，
即SYN queue

全连接状态；
指的是TCP建立连接后ESTABLISHED。TCP的连接状态从服务器SYN+ACK响应客户端后，收到客户端返回的ACK
之前一直保留在半连接队列中。当服务器收到ACK后，则将半连接队列中的套接字信息加载到全连接队列中去。


从 linux 内核 2.2 开始，系统分离成两个 backlog 分别限制半连接（SYN_RCVD 状态）队列大小和全连接（ESTABLISHED 状态）队列大小。



半连接队列：

SYN queue 队列长度由 net.ipv4.tcp_max_syn_backlog 指定，默认值是根据内存大小而定，如果系统内存超过 128MB，默认值为 1024，低于 128MB 时为 128

SYN_COOKIE原理：
当半连接队列已满时候，SYN cookies并不丢弃SYN请求，而是将源目的IP
源目的的端口号，接收到client的初始序列号一起进行hash运算，并加密得到server
端的初始序列号，称之为cookie。server端在发送初始序列号为cookie的SYN+ACK包。，会将分配的连接请求块释放。
如果接收到 client 端的 ACK 包，server 端将 client 端的 ACK 序列号减 1 得到的值，与上述要素 hash 运算得到的值比较，如果相等，直接完成三次握手，构建新的连接




全连接队列(Accept queue)

在第三次握手时，当server端接收到ACK之后，会进入一个叫accept queue中，
accept queue的队列长度由 listen函数的backlog参数和默认参数取最小值


当accept queue满了之后，即使client端继续向server返送ACK也不会被响应，
此时的ListenOverflows + 1, 系统会根据默认参数tcp_abort_on_overflow 决定返回值。

值为0表示 直接丢弃这个ACK, 但是连接信息不会从SYN queue队列中移除。当服务器最终丢弃这个ACK包
的时候，系统会根据参数重新向client发送SYN+ACK包。而client就会受到多个
SYN+ACK的包，会认为之前的ACK包丢包了，所以又重新发送ACK包。
当accept queue有空闲空间的时候最终完成连接。如果始终满员，则最终发送RST重置报文

如果tcp_abort_on_overflow 为1的时候，server端直接发送RST报文通知client。与此同时，
client 则会分别返回 read timeout 或者 connection reset by peer

智能指针的作用就是管理一个指针，申请的空间忘记释放，造成内存泄漏。
使用智能指针这种RAII思想的指针就可以避免这个问题。

1. auto_ptr
采用所有权模式。赋值的时候进行所有权转移，赋值的那个对象维护的就是空指针，
访问会存在访问崩溃的现象。

2. unque_ptr
实现独占式拥有或严格拥有的概念，保证同一时间只有一个指针指针对象可以指向该对象。
对于资源泄漏特别有用
编译器认为p3 = p4非法，避免了p4不在指向有效数据的问题。因此unique_ptr更加的安全。

unique_ptr还有更加聪明的地方：
如果源unique_ptr对象是一个临时右值的话，编译器允许这么做。
如果源unque_ptr对象是一个已存在一段时间，编译器不允许这么做。

3. shared_ptr
shared_ptr实现共享式拥有的概念。多个职能指针可以指向相同的对象。
引出了引用计数的概念。当对象和其相关资源会在最后一个引用被销毁时释放，
也就是当引用计数为0时，会释放这个对象的相关资源。它使用计数机制来表明
资源被几个指针所共享。通过成员函数use_count查看资源的所有者个数。
shared_ptr是为了解决auto_ptr在对象所有权上的局限性，使用引用计数机制可以实现
共享的制作你能指针，

4.weak_ptr是一种不控制对象生命周期的智能指针，是一种弱指针，指向一个shared_ptr管理的对象。
只是提供一个访问手段进行访问对象。weak_ptr的引用时来协助shared_ptr工作的。
它可以从一个shared_ptr对象构造。它的构造与析构不会引起引用计数的增加或减少。解决
shared_ptr循环引用的问题产生的。 如果两个shared_ptr相互引用，那么这两个指针的引用
计数永远不可能下降为 0，资源永不释放。它是对对象的一种弱引用。



Linux的内存不足时会发生什么？

使用交换分区的 内存
如果你开启了swap，类似于Windows的虚拟内存，就是当内存不足的时候，把一部分硬盘空间虚拟成内存使用,从而解决内存容量不足的情况。



内存与外存是如何交流沟通的？

计算机内存是指： 存储器芯片，直接与CPU相连接，CPU在读写内存是，速度较快
计算机外存是指： 输出设备 与 输入设备 硬盘。 外存储器的功能长期存放程序与数据。
外存的上的信息主要是由操作系统来管理的。外存一般只与内存做信息交换。

中bai央处理器（就是经常说的CPU）命令将硬盘数du据读入内存，好提供给自己处理计算，然后结果再返回内存，再保存到硬盘





